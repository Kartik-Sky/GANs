{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import Discriminator,Generator,initialize_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "lr= 2e-4\n",
    "batch_size=128\n",
    "img_size=64\n",
    "channels_img= 1\n",
    "z_dim = 100\n",
    "num_epochs = 5\n",
    "features_disc = 64\n",
    "features_gen= 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5 for _ in range(channels_img)],[0.5 for _ in range(channels_img)],) # For the number of channels\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = datasets.MNIST(root=\"dataset/\",train=True, transform=transforms,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader= DataLoader(dataset,batch_size=batch_size,shuffle= True)\n",
    "gen = Generator(z_dim,channels_img,features_gen).to(device)\n",
    "disc= Discriminator(channels_img,features_disc).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "opt_disc= optim.Adam(disc.parameters(),lr=lr, betas=(0.5,0.999))\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise = torch.randn(32,z_dim,1,1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step=0\n",
    "\n",
    "gen.train()\n",
    "disc.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5] Batch 0/469 \\ Loss D:0.6960, Loss G:  0.7756\n",
      "Epoch [0/5] Batch 100/469 \\ Loss D:0.0142, Loss G:  4.1699\n",
      "Epoch [0/5] Batch 200/469 \\ Loss D:0.7127, Loss G:  0.8759\n",
      "Epoch [0/5] Batch 300/469 \\ Loss D:0.5763, Loss G:  1.7172\n",
      "Epoch [0/5] Batch 400/469 \\ Loss D:0.9892, Loss G:  1.9411\n",
      "Epoch [1/5] Batch 0/469 \\ Loss D:0.6179, Loss G:  1.6491\n",
      "Epoch [1/5] Batch 100/469 \\ Loss D:0.6273, Loss G:  0.7653\n",
      "Epoch [1/5] Batch 200/469 \\ Loss D:0.6518, Loss G:  1.2517\n",
      "Epoch [1/5] Batch 300/469 \\ Loss D:0.6316, Loss G:  0.5411\n",
      "Epoch [1/5] Batch 400/469 \\ Loss D:0.6523, Loss G:  0.6210\n",
      "Epoch [2/5] Batch 0/469 \\ Loss D:0.6374, Loss G:  1.2007\n",
      "Epoch [2/5] Batch 100/469 \\ Loss D:0.5933, Loss G:  0.5722\n",
      "Epoch [2/5] Batch 200/469 \\ Loss D:0.6418, Loss G:  1.2464\n",
      "Epoch [2/5] Batch 300/469 \\ Loss D:0.6365, Loss G:  0.7885\n",
      "Epoch [2/5] Batch 400/469 \\ Loss D:0.5585, Loss G:  1.1718\n",
      "Epoch [3/5] Batch 0/469 \\ Loss D:0.5417, Loss G:  1.3982\n",
      "Epoch [3/5] Batch 100/469 \\ Loss D:0.4983, Loss G:  2.2339\n",
      "Epoch [3/5] Batch 200/469 \\ Loss D:0.5247, Loss G:  2.1914\n",
      "Epoch [3/5] Batch 300/469 \\ Loss D:0.5467, Loss G:  1.1885\n",
      "Epoch [3/5] Batch 400/469 \\ Loss D:0.3181, Loss G:  2.0987\n",
      "Epoch [4/5] Batch 0/469 \\ Loss D:0.3498, Loss G:  1.6474\n",
      "Epoch [4/5] Batch 100/469 \\ Loss D:0.4901, Loss G:  3.2837\n",
      "Epoch [4/5] Batch 200/469 \\ Loss D:0.3205, Loss G:  1.8276\n",
      "Epoch [4/5] Batch 300/469 \\ Loss D:0.4056, Loss G:  2.7634\n",
      "Epoch [4/5] Batch 400/469 \\ Loss D:0.5071, Loss G:  0.5003\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real,_) in enumerate(loader):\n",
    "        real= real.to(device)\n",
    "        noise = torch.randn((batch_size,z_dim,1,1)).to(device)\n",
    "        fake= gen(noise)\n",
    "        ### Train Discriminator max log(D(x)) + log(1-D(G(z)))\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real,torch.ones_like(disc_real))\n",
    "\n",
    "        disc_fake= disc(fake).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake)/2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator min log(1-D(G(z))) <-> max log(D(G(z)))\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx%100 == 0: \n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\ Loss D:{loss_disc:.4f}, Loss G: {loss_gen: .4f}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                fake = gen(fixed_noise)\n",
    "\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32],normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32],normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\",img_grid_real,global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "            \n",
    "            step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_fake.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_real.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
